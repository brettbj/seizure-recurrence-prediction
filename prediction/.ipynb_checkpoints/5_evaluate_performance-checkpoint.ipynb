{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b36c0d-fc06-4b6e-86d3-4cae8fac1ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:23:24.465754Z",
     "iopub.status.busy": "2022-09-01T04:23:24.465341Z",
     "iopub.status.idle": "2022-09-01T04:23:30.136262Z",
     "shell.execute_reply": "2022-09-01T04:23:30.135064Z",
     "shell.execute_reply.started": "2022-09-01T04:23:24.465670Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/models/cat-scratch-longformer/clean-model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "neurology_notes = ['NOTE:125942859', 'NOTE:2820514', 'NOTE:4127998', 'NOTE:4127189', 'NOTE:3817544', 'NOTE:4776343', 'NOTE:67621192', 'NOTE:4127201', 'NOTE:4128000', 'NOTE:4127729', 'NOTE:4127835', 'NOTE:4127923', 'NOTE:4293224', 'NOTE:4127989', 'NOTE:4127595', 'NOTE:4776342', 'NOTE:4293221', 'NOTE:4633365', 'NOTE:4127190', 'NOTE:4127226', 'NOTE:4127203', 'NOTE:4127515', 'NOTE:4127192', 'NOTE:4127524', 'NOTE:4127586', 'NOTE:4293218', 'NOTE:3827999', 'NOTE:4127522', 'NOTE:4127837', 'NOTE:4127194', 'NOTE:599038309', 'NOTE:4127597', 'NOTE:4127999', 'NOTE:4293225', 'NOTE:4127992', 'NOTE:3828001', 'NOTE:4293226', 'NOTE:3755582', 'NOTE:164478027', 'NOTE:125943072', 'NOTE:4776258', 'NOTE:4127227', 'NOTE:599038319', 'NOTE:4127202', 'NOTE:490360275', 'NOTE:4127457', 'NOTE:22652867', 'NOTE:16187985', 'NOTE:400739364', 'NOTE:4776344', 'NOTE:4776072', 'NOTE:4127995', 'NOTE:4128007', 'NOTE:4127204', 'NOTE:4127191', 'NOTE:4127195']\n",
    "discharge_notes = ['NOTE:3710478', 'NOTE:67621090', 'NOTE:15612283', 'NOTE:15585515', 'NOTE:3710477', 'NOTE:15587049', 'NOTE:15587406', 'NOTE:15612287', 'NOTE:189094536', 'NOTE:15588370', 'NOTE:15588192', 'NOTE:67621087', 'NOTE:15586337', 'NOTE:153048767', 'NOTE:15587712', 'NOTE:189094539', 'NOTE:97195725', 'NOTE:618403281', 'NOTE:122778232']\n",
    "eeg_notes = ['NOTE:3691367', 'NOTE:3691278', 'NOTE:4120166', 'NOTE:4120168', 'NOTE:3691374', 'NOTE:4120169']\n",
    "mri_notes = ['NOTE:83328334', 'NOTE:83328424', 'NOTE:3447280', 'NOTE:83328328', 'NOTE:83328617', 'NOTE:83328304', 'NOTE:64217783', 'NOTE:251612637', 'NOTE:251612643', 'NOTE:83328337', 'NOTE:3447282', 'NOTE:83328313', 'NOTE:64217795', 'NOTE:83328427', 'NOTE:83328433', 'NOTE:3447264', 'NOTE:3447296', 'NOTE:64217779', 'NOTE:64217573', 'NOTE:8007688', 'NOTE:3447291', 'NOTE:202592750', 'NOTE:83328370', 'NOTE:83328406', 'NOTE:3447318', 'NOTE:83328325', 'NOTE:64217811', 'NOTE:83328403', 'NOTE:64217538', 'NOTE:83328436', 'NOTE:83328322', 'NOTE:4106734', 'NOTE:83328385', 'NOTE:4106510', 'NOTE:64217571', 'NOTE:64217568', 'NOTE:3447321', 'NOTE:3447275', 'NOTE:3447320', 'NOTE:8007690', 'NOTE:64217799', 'NOTE:83328448', 'NOTE:64217642', 'NOTE:83328292', 'NOTE:251612640', 'NOTE:3447290', 'NOTE:3447301', 'NOTE:3447317', 'NOTE:83328621', 'NOTE:83328412', 'NOTE:83328367', 'NOTE:3447300', 'NOTE:333730849', 'NOTE:3447289', 'NOTE:11921317', 'NOTE:3447293', 'NOTE:83328382', 'NOTE:100343890', 'NOTE:4106495', 'NOTE:83328280', 'NOTE:83328286', 'NOTE:8007698', 'NOTE:3447292', 'NOTE:83328400', 'NOTE:3447306', 'NOTE:8007683', 'NOTE:64217638', 'NOTE:3447266', 'NOTE:3447283', 'NOTE:345927837', 'NOTE:83328379', 'NOTE:83328331', 'NOTE:3447322', 'NOTE:83328373', 'NOTE:3447323', 'NOTE:64217409', 'NOTE:83328363', 'NOTE:64217323', 'NOTE:3447260', 'NOTE:3447313', 'NOTE:64217561', 'NOTE:8007708', 'NOTE:83328298', 'NOTE:8007672', 'NOTE:83328430', 'NOTE:3447308', 'NOTE:3447285', 'NOTE:345927816', 'NOTE:3447314', 'NOTE:4106731', 'NOTE:333730843', 'NOTE:83328301', 'NOTE:64217416', 'NOTE:64217539', 'NOTE:64217666', 'NOTE:64217530', 'NOTE:64217393', 'NOTE:64217384', 'NOTE:8007725', 'NOTE:3447302', 'NOTE:11921316', 'NOTE:3447258']\n",
    "ct_notes = ['NOTE:3446996', 'NOTE:3447017', 'NOTE:202592738', 'NOTE:3446983', 'NOTE:3446993', 'NOTE:3447020', 'NOTE:3446980', 'NOTE:3447006', 'NOTE:3446997', 'NOTE:3446998', 'NOTE:4873824', 'NOTE:3446982', 'NOTE:230601754', 'NOTE:3446974', 'NOTE:202592729', 'NOTE:3447012', 'NOTE:3446985', 'NOTE:3446999', 'NOTE:64217632', 'NOTE:4873823', 'NOTE:3447011', 'NOTE:3447004', 'NOTE:230601760', 'NOTE:428074121', 'NOTE:244897858', 'NOTE:64217494', 'NOTE:3446990', 'NOTE:463436530', 'NOTE:64217627', 'NOTE:3446991', 'NOTE:64217513', 'NOTE:64217581', 'NOTE:3447015', 'NOTE:8007643', 'NOTE:3447008', 'NOTE:428074112', 'NOTE:452620691', 'NOTE:64217599', 'NOTE:83328241', 'NOTE:3446979', 'NOTE:3447018', 'NOTE:64217357', 'NOTE:3446995']\n",
    "all_relevant = neurology_notes + discharge_notes + eeg_notes + mri_notes + ct_notes\n",
    "\n",
    "note_cat_dict = {\n",
    "    'neurology_notes': neurology_notes,\n",
    "    'discharge_notes': discharge_notes,\n",
    "    'eeg_notes': eeg_notes,\n",
    "    'mri_notes': mri_notes,\n",
    "    'ct_notes': ct_notes,\n",
    "    'all_relevant': all_relevant\n",
    "}\n",
    "\n",
    "key = 'mri_notes'\n",
    "base_path = f\"\"\"/n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/classifier-input\"\"\"\n",
    "fname = f\"{base_path}/{key}_classifier_no_filter_input.csv\"\n",
    "\n",
    "df = pd.read_csv(fname)\n",
    "input_df = df[~df['text'].isna()]\n",
    "\n",
    "label_df = pd.read_csv('./data/labels.csv')\n",
    "label_df.fillna(0, inplace=True)\n",
    "label_df.describe()\n",
    "label_cols = label_df.columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "vocab_sizek = 52\n",
    "base_path = f\"\"\"/n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/models/cat-scratch-longformer\"\"\"\n",
    "output_comb_dir = f\"{base_path}/clean-model\"\n",
    "print(output_comb_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136f2670-2036-4784-b386-e4197b3344fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:29.179839Z",
     "iopub.status.busy": "2022-09-01T04:30:29.179446Z",
     "iopub.status.idle": "2022-09-01T04:30:29.184397Z",
     "shell.execute_reply": "2022-09-01T04:30:29.183626Z",
     "shell.execute_reply.started": "2022-09-01T04:30:29.179808Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_round=2\n",
    "# checkpoint = \"checkpoint-81000\"\n",
    "max_token_length=4096\n",
    "\n",
    "trained_tok_file = f\"{base_path}/tokenizers/bpe_no_filter_{vocab_sizek}_all_relevant.json\"\n",
    "# model_wcheckpoint = f\"{output_comb_dir}/{training_round}/{checkpoint}\"\n",
    "model_wcheckpoint = f\"{output_comb_dir}/{training_round}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acaf6466-c528-4dd2-be15-09c7b1a4f7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:29.858276Z",
     "iopub.status.busy": "2022-09-01T04:30:29.857901Z",
     "iopub.status.idle": "2022-09-01T04:30:29.862261Z",
     "shell.execute_reply": "2022-09-01T04:30:29.861508Z",
     "shell.execute_reply.started": "2022-09-01T04:30:29.858247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_wcheckpoint = f\"{output_comb_dir}/2/checkpoint-15000\"\n",
    "# model_dict = {\n",
    "#                 \"bch\":[trained_tok_file, model_wcheckpoint],\n",
    "#                 \"clinical-longformer\": ['yikuan8/Clinical-Longformer', 'yikuan8/Clinical-Longformer']\n",
    "# }\n",
    "\n",
    "\n",
    "# bch_tokenizer = Tokenizer.from_file(trained_tok_file)\n",
    "# bch_model = AutoModelForMaskedLM.from_pretrained(model_wcheckpoint)\n",
    "\n",
    "# cl_tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "# cl_model = AutoModelForMaskedLM.from_pretrained(\"yikuan8/Clinical-Longformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30199af4-e5e0-4740-b48a-c4f4d25584bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:30.375287Z",
     "iopub.status.busy": "2022-09-01T04:30:30.375005Z",
     "iopub.status.idle": "2022-09-01T04:30:30.589765Z",
     "shell.execute_reply": "2022-09-01T04:30:30.588754Z",
     "shell.execute_reply.started": "2022-09-01T04:30:30.375261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/models/cat-scratch-longformer/clean-model/2\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "config.json   pytorch_model.bin  scaler.pt     trainer_state.json\n",
      "optimizer.pt  rng_state.pth\t scheduler.pt  training_args.bin\n"
     ]
    }
   ],
   "source": [
    "print(model_wcheckpoint)\n",
    "!ls /n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/models/cat-scratch-longformer/all_relevant-model/0/checkpoint-90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa0696a6-0e49-4d10-a50a-0d64d376ba52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:30.873026Z",
     "iopub.status.busy": "2022-09-01T04:30:30.872659Z",
     "iopub.status.idle": "2022-09-01T04:30:31.090042Z",
     "shell.execute_reply": "2022-09-01T04:30:31.089042Z",
     "shell.execute_reply.started": "2022-09-01T04:30:30.872982Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/models/cat-scratch-longformer/tokenizers/bpe_no_filter_52_all_relevant.json\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "bpe_no_filter_52_all_relevant.json  bpe_no_filter_52_mri_notes.json\n",
      "bpe_no_filter_52_ct_notes.json\t    bpe_no_filter_52_neurology_notes.json\n"
     ]
    }
   ],
   "source": [
    "print(trained_tok_file)\n",
    "!ls /n/data1/hms/dbmi/beaulieu-jones/lab/epilepsy-transformer/models/cat-scratch-longformer/tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a1d5ff3-47cb-4669-a8af-f83c1868084a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:31.463852Z",
     "iopub.status.busy": "2022-09-01T04:30:31.463505Z",
     "iopub.status.idle": "2022-09-01T04:30:34.024547Z",
     "shell.execute_reply": "2022-09-01T04:30:34.023756Z",
     "shell.execute_reply.started": "2022-09-01T04:30:31.463820Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "bch_tokenizer = Tokenizer.from_file(trained_tok_file)\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
    "bch_fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=bch_tokenizer, model_max_length=max_token_length)\n",
    "bch_fast_tokenizer.add_special_tokens({'pad_token': '[PAD]', 'mask_token': '[MASK]'})\n",
    "\n",
    "bch_model = AutoModelForMaskedLM.from_pretrained(model_wcheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83bfe3e8-de82-482a-88a9-f181ec7b2e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:47.965315Z",
     "iopub.status.busy": "2022-09-01T04:30:47.964737Z",
     "iopub.status.idle": "2022-09-01T04:30:48.435336Z",
     "shell.execute_reply": "2022-09-01T04:30:48.434396Z",
     "shell.execute_reply.started": "2022-09-01T04:30:47.965271Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient experienced a ? seizure.\n",
      "Patient experienced a  grand seizure.\n",
      "Patient experienced a  \" seizure.\n",
      "Patient experienced a  ' seizure.\n",
      "Patient experienced a / seizure.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bch_fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=bch_model,\n",
    "    tokenizer=bch_fast_tokenizer\n",
    ")\n",
    "\n",
    "mask = bch_fast_tokenizer.mask_token\n",
    "# sequence = f\"Patient experienced a focal {mask}\"\n",
    "# sequence = f\"The EEG showed {mask}\"\n",
    "sequence = f\"Patient experienced a {mask} seizure.\"\n",
    "# sequence = f\"The active ingredient in keppra is {mask}.\"\n",
    "# sequence = f\"levitercetam is used to treat {mask}.\"\n",
    "# sequence = f\"levitercetam to be taken {mask}.\"\n",
    "# sequence = f\"Keppra is used to treat {mask}.\"\n",
    "# sequence = f\"patient has a high likelihood of additional seizures so a {mask} was ordered.\"\n",
    "\n",
    "result = bch_fill_mask(sequence)\n",
    "for r in result:\n",
    "    print(sequence.replace(bch_fast_tokenizer.mask_token, r['token_str']))\n",
    "    # print(r['token_str'], r['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7792d917-a735-4cb5-9e59-aa637bc0422d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T04:30:56.554000Z",
     "iopub.status.busy": "2022-09-01T04:30:56.553539Z",
     "iopub.status.idle": "2022-09-01T04:31:01.020354Z",
     "shell.execute_reply": "2022-09-01T04:31:01.019569Z",
     "shell.execute_reply.started": "2022-09-01T04:30:56.553962Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient experienced a  generalized seizure\n",
      "Patient experienced a  witnessed seizure\n",
      "Patient experienced a  focal seizure\n",
      "Patient experienced a  second seizure\n",
      "Patient experienced a  minute seizure\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "cl_tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"yikuan8/Clinical-Longformer\",\n",
    "    tokenizer=\"yikuan8/Clinical-Longformer\"\n",
    ")\n",
    "\n",
    "mask = cl_tokenizer.mask_token\n",
    "# sequence = f\"Patient experienced a focal {mask}\"\n",
    "# sequence = f\"The EEG showed {mask}\"\n",
    "sequence = f\"Patient experienced a {mask} seizure\"\n",
    "# sequence = f\"The generic drug name for keppra is {mask}.\"\n",
    "# sequence = f\"levitercetam is used to treat {mask}.\"\n",
    "# sequence = f\"keppra is used to treat {mask}.\"\n",
    "# sequence = f\"levitercetam to be taken {mask}.\"\n",
    "# sequence = f\"patient has a high likelihood of additional seizures so a {mask} was ordered.\"\n",
    "\n",
    "result = fill_mask(sequence)\n",
    "for r in result:\n",
    "    print(sequence.replace(cl_tokenizer.mask_token, r['token_str']))\n",
    "    # print(r['token_str'], r['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e93a2-ae43-4084-b119-345dfa4bf729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
